# Multi-Level Cache Benchmark Report

**Date:** 2025-11-26 20:09:37
**Environment:** Spring Boot 3.3.0, Java 21, MySQL 8.0, Redis 7

---

## Executive Summary

| Metric | Value |
|--------|-------|
| Response Time (Cold → Warm) | **2ms → 4ms** |
| Performance Improvement | **.5x faster** |
| Database Load Reduction | **100%** |
| Peak Throughput | **17012.59 req/s** |

---

## Response Time Analysis

### Cold Cache (Database-only)
- Average Response Time: **2ms**
- Every request hits the database
- Baseline performance without caching

### Warm Cache (Multi-Level)
- Average Response Time: **4ms**
- L1 (Caffeine) + L2 (Redis) active
- **.5x improvement**

---

## Cache Performance

### L1 Cache (Caffeine - In-Memory)
- Hit Ratio: **100.00%**
- Latency: ~1-2ms
- Scope: Per-instance

### L2 Cache (Redis - Distributed)
- Hit Ratio: **68.00%**
- Latency: ~10-15ms
- Scope: Shared across instances

---

## Database Impact

- **100%** reduction in database queries
- Queries only on cache miss (cold start or TTL expiration)
- Significant reduction in connection pool usage

---

## Load Test Results

| Test Scenario | Requests | Concurrency | Avg Response | RPS |
|---------------|----------|-------------|--------------|-----|
| Cold Cache | 20 | 1 | 2ms | - |
| Warm Cache | 1000 | 50 | 4ms | 10229.34 |
| High Load | 5000 | 100 | - | 17012.59 |

---

## Conclusion

The multi-level caching implementation successfully:

✅ Reduced API response time from **2ms to 4ms** (.5x faster)
✅ Decreased database load by **100%**
✅ Achieved L1 cache hit ratio of **100.00%**
✅ Sustained **17012.59 requests/second** under load

---

*Generated by benchmark.sh on Wed Nov 26 20:09:37 GMT 2025*
